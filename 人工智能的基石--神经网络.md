# 神经网络的终极形态——脉冲神经网络

## 什么是神经网络

神经网络，也称为人工神经网络 (ANN) 或模拟神经网络 (SNN)，是[机器学习](https://www.ibm.com/cn-zh/cloud/learn/machine-learning)的子集，并且是[深度学习](https://www.ibm.com/cloud/learn/deep-learning)算法的核心。其名称和结构是受人类大脑的启发，模仿了生物神经元信号相互传递的方式。

从数学上来讲,神经网络的运作方式就是高阶矩阵相乘.



## 神经网络能做什么

### 语音

1. 音频分类

   <img src="http://124.223.88.45:9999/86300bef-6e47-4d8c-b107-ac8c16a6394d.png" alt="音频分类" style="zoom:50%;" />

2. 音频指纹识别

   ![音频指纹](http://124.223.88.45:9999/c992d5a2-8409-4c5b-ab83-d06267a40fcc.png)

3. 音乐推荐

   <img src="http://124.223.88.45:9999/222eaa55-a81b-4b3e-bb0a-67e323d07c20.png" alt="image-20220902215412111" style="zoom:50%;" />

4. 语音转文字

   <img src="http://124.223.88.45:9999/39a20227-fed1-4f54-8e1e-56972904d7ec.png" alt="image-20220902220029154" style="zoom:50%;" />

### 文字

1. 文本生成

   [狗屁不通文章生成器](https://suulnnka.github.io/BullshitGenerator/index.html)

2. 信息抽取

   > 把文本里包含的信息进行结构化处理

   <img src="http://124.223.88.45:9999/9583797a-bd62-4cc1-afaa-b019d91993c3.jpeg" alt="信息抽取" style="zoom:50%;" />

3. 情绪分析

   <img src="http://124.223.88.45:9999/06be2849-2a14-49b3-8bd2-5d58e0e77fea.png" alt="情感分析" style="zoom:50%;" />

   [讯飞情感分析开放平台](https://www.xfyun.cn/service/emotion-analysis)

4. 机器翻译

   <img src="http://124.223.88.45:9999/6f472169-0015-4d2e-bce4-ba0a5478ae5b.png" alt="image-20220902232113881" style="zoom:50%;" />

### 图像&视频

1. 图像风格迁移

   [animegan](https://animegan.js.org/)

2. 图像生成

   [Google imageGan](https://imagen.research.google/)

3. 图像分类

   <img src="http://124.223.88.45:9999/4456e9ee-8915-47cc-8ad4-09ef1ebfaea8.jpeg" alt="图像分类" style="zoom:50%;" />

4. 目标检测

   <img src="http://124.223.88.45:9999/3df720d1-ac0f-4bef-afa6-4303f48a99e3.jpeg" alt="目标检测" style="zoom:50%;" />

5. 实例分割

   <img src="http://124.223.88.45:9999/3da82ec0-6bc4-4b9e-9b29-9638c0f6f0e0.gif" alt="实时目标追踪" style="zoom:150%;" />

6. 目标跟踪

   <img src="http://124.223.88.45:9999/2428ee7a-a5b9-4644-bb00-d8c7a1b69324.gif" alt="目标跟踪" style="zoom:150%;" />

7. 场景文字识别

<img src="http://124.223.88.45:9999/2595436c-be09-4f78-9137-a00b1c538562.png" alt="票据识别" style="zoom: 33%;" />

8. 人体关键点检测

   <img src="http://124.223.88.45:9999/5804e3d2-3456-4a34-9c0b-5ff28f5f9e05.gif" alt="人体关键点检测" style="zoom:50%;" />

## 回归本质–神经网络解决了什么问题

1. 分类

   <img src="/Users/lxs/PycharmProjects/share/images/share/classify.gif" alt="classify" style="zoom: 67%;" />

2. 回归

   <img src="/Users/lxs/PycharmProjects/share/images/share/regression.gif" alt="regression" style="zoom: 67%;" />

## 前世今生–神经网络的进化之路

### 时间轴

1. 萌芽期 1940年代

- M-P模型(1943)

- Hebb学习规则(1945)

2. 繁荣期 1958~1969年

- 感知机(1958)
- Adaline(1960)
- Perceptron(1969)

3. 冰河期 1969~1985年
4. 繁荣期 1985~1995年

- Hopfield(1983)
- BP(1986)
- SVM支持向量机(1995)

5. 沉寂期 1995~2010年

6. 繁荣期 2010~now

- LeNet
- AlexNet
- GoogleNet
- ResNet系列
- VGG系列
- RNN系列
- YOLO系列
- …

### 大事记

1. Hebb法则, 提出理论依据

   生物神经元模型:

   <img src="http://124.223.88.45:9999/a6052472-398b-4bb5-8738-a141cf92645a.png" alt="生物神经元模型" style="zoom:50%;" />

   电路模型:

   <img src="http://124.223.88.45:9999/778c7224-0eac-41c4-a438-a50dc9be048c.png" alt="神经元电路模型" style="zoom: 33%;" />

   电流公式
   $$
   I\left(t\right)=I_R\left(t\right)+I_C\left(t\right)
   $$
   欧姆定律
   $$
   I\left(t\right)=\ \frac{U\left(t\right)-U_{reset}}{R}+\ C\frac{dU(t)}{dt}
   $$
   引入时间常数
   $$
   \tau_m\frac{dU(t)}{dt}=\ -(U\left(t\right)-U_{reset})+\ RI(t)
   $$
   输入X=RI
   $$
   \tau_m\frac{dU(t)}{dt}=\ -(U\left(t\right)-U_{reset})+\ X(t)
   $$
   离散化
   $$
   \tau_m(U[t]-U[t-1])=-(U[t-1]-Ureset)+X[t]
   $$
   瞬时模电压
   $$
   U[t]=f(U[t-1],X[t])=U[t-1]+1τm(-(U[t-1]-Ureset)+X[t])
   $$
   模电压不能一直上升,当到达激发阈值时,会发放脉冲,模电压极速降低

   ![发放脉冲时模电压变化情况](http://124.223.88.45:9999/48032c22-41be-4fd4-955b-28b392153a87.gif)

2. 感知机,第一次尝试

   > 感知机是Frank Rosenblatt于1957年康奈尔航空实验室时发明的一种人工神经网络,被视为最简单形式的前馈神经网络,是一种二元线性分类器.

将输入实例在超平面上进行分类.

<img src="http://124.223.88.45:9999/81a28afa-b97c-4dbf-9eef-29f5b9457184.png" alt="感知机模型" style="zoom: 33%;" />
$$
f(x)= \begin{cases}1 & \text { if } w \cdot x+b>0 \\ 0 & \text { else }\end{cases}
$$
多层感知机

<img src="http://124.223.88.45:9999/ad08e09b-eb93-48ba-ae9d-1d9f28f39a06.gif" alt="多层感知机" style="zoom: 67%;" />

3. BP,注入灵魂,使用至今

   > 1986年,Geoffrey Hinton提出了BP,BP(Backpropagation)不是一种网络,而是一种训练网络的方法.和BP一同出现的还有激活函数

   Sigmoid激活函数

   <img src="http://124.223.88.45:9999/feb88cf0-316b-494c-9474-ea87ab69f7fe.png" alt="image-20220903153158304" style="zoom:25%;" />

   网络的学习过程:

   - 样本输入
   - 正向计算
   - 比较输出,计算损失
   - 计算梯度(偏导数),反向传播
   - 权重修正

<img src="https://1.cms.s81c.com/sites/default/files/2021-01-06/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork-WHITEBG.png" alt="前馈神经网络的输入层、隐藏层和输出层的可视图" style="zoom: 33%;" />

梯度下降

<img src="https://likeitea-1257692904.cos.ap-guangzhou.myqcloud.com/liketea_blog/source.gif" alt="img" style="zoom: 67%;" />

![开始解决复杂问题](http://124.223.88.45:9999/a90ba069-c904-442b-95b3-45296264fdf6.gif)

5. LeNet,第一个卷积神经网络

   引入了卷积和池化的概念

   相对比多层感知机,参数减少,精度提升

   

   ![LeNet](http://124.223.88.45:9999/6b48c081-f62b-45d1-871d-a1ab1f6d9005.png)

   

6. AlexNet,神经网络开始“文艺复兴”

   AlexNet在ImageNet LSVRC-2012（Large Scale Visual Recognition Competition）赢得第一名，并且错误率只有15.3%（第二名是26.2%）

   <img src="http://124.223.88.45:9999/b1c8ac8c-e5b4-495e-9d40-f4a209c04c17.jpg" alt="AlexNet网络结构图" style="zoom: 67%;" />

7. FasterRCNN,开山之作,影响延续至今

   2015年华人主导研究的目标检测算法

   <img src="http://124.223.88.45:9999/62268be0-8a73-4918-b75a-daafe079c528.png" alt="image-20220903164011810" style="zoom:50%;" />

   

   <img src="http://124.223.88.45:9999/8204cc3c-f9b9-4e49-9e8c-d272f88452c6.png" alt="fasterRCNN" style="zoom:50%;" />



之前: SPP滑窗 + CNN分类

现在: RPN筛选 + CNN分类 

## 神经网络的一般组成

### 卷积

> 卷积本质上是一种数字滤波器,和传统的数字滤波器之间的不同在于卷积的核(即权重)在训练的过程中是动态变化的

![卷积层运算过程](http://124.223.88.45:9999/083d847f-8d14-4082-bbb1-3be49c3c6beb.gif)

卷积的意义:

- 局部连接,精确感受野,提取特征
- 权值共享,减小参数量,加速计算

### 全连接

<img src="https://easyai.tech/wp-content/uploads/2022/08/c1a6d-2019-06-19-quanlianjie.png" alt="全连接层" style="zoom:70%;" />

全连接层的作用

- 将特征映射到样本标记空间
- 汇聚信息,增加非线性**表达能力**

### 池化

> 池化简单来讲就是下采样,可以大大的降低数据的维度

<img src="https://easyai.tech/wp-content/uploads/2022/08/3fd53-2019-06-19-chihua.gif" alt="池化层过程" style="zoom: 67%;" />

池化的意义:

- 提供一定的特征不变性,池化在层的维度对信息进行汇合
- 维度约减,提升模型感受野,减少参数量

### 激活函数

<img src="http://124.223.88.45:9999/f46bca4c-4b85-4f23-869b-218fd036deef.png" alt="激励函数" style="zoom:72%;" />

1. 为什么要有激活函数?

   - 为网络引入非线性,解决线性不可分问题

     线性可分问题

     ![线性可分](http://124.223.88.45:9999/28d0e954-53a7-4327-a278-0accc25ea2ef.jpg)

     异或问题

     | x    | y    | z    |
     | ---- | ---- | ---- |
     | 1    | 0    | 1    |
     | 0    | 1    | 1    |
     | 1    | 1    | 0    |
     | 0    | 0    | 1    |

     <img src="http://124.223.88.45:9999/7c2717e7-e2a3-4f72-af43-3f11ff44c9a7.jpg" alt="异或平面" style="zoom: 67%;" />

     

     <img src="http://124.223.88.45:9999/58525cd6-848d-40e4-bfdb-ca063c3f4d6c.png" alt="image-20220904222133771" style="zoom:50%;" />

   - 模拟生物神经元的积累放电过程

   

   

## 损失函数

> **损失函数**用来评价模型的**预测值**和**真实值**不一样的程度，损失函数越好，通常模型的性能越好。不同的模型通常使用不同的损失函数.

1. 0-1损失函数
   $$
   L(Y, f(X))=\left\{\begin{array}{l}
   1, Y \neq f(X) \\
   0, Y=f(X)
   \end{array}\right.
   $$

- 是一个非凸损失函数
- **感知机**就是用的这种损失函数

2. 绝对值损失函数

$$
L(Y, f(x))=|Y-f(x)|
$$

3. 对数损失函数

4. 平方损失函数

5. 指数损失函数

6. 交叉熵损失函数

   <img src="https://yifeitao.com/assets/images/loss.png" alt="二分类问题的评分值与损失函数- 次生进化" style="zoom:72%;" />

## 人工智能OR人工智障

1. 落地艰难
2. 数据
3. 算力
4. 生物仿真性



